# XAI_From_Classical_Models_to_LLMs

![License](https://img.shields.io/badge/License-MIT-green)
[![arXiv](https://img.shields.io/badge/arXiv-2412.00800-B31B1B.svg)](https://arxiv.org/abs/2412.00800)
[![DOI](https://img.shields.io/badge/DOI-10.48550/arXiv.2412.00800-blue)](https://doi.org/10.48550/arXiv.2412.00800)

This repository contains the accompanying code and resources for the book **"A Comprehensive Guide to Explainable AI: From Classical Models to LLMs"**.

## About the Book

**A Comprehensive Guide to Explainable AI** addresses the critical need for transparency and interpretability in AI systems. This book bridges foundational concepts with advanced methodologies, offering a deep dive into the following topics:

- **Traditional Models**: Interpretability in Decision Trees, Linear Regression, Support Vector Machines (SVMs).
- **Deep Learning Models**: Explainability for CNNs, RNNs, and Large Language Models (LLMs) like BERT, GPT, and T5.
- **Practical Techniques**: SHAP, LIME, Grad-CAM, counterfactual explanations, causal inference.
- **Case Studies**: Applications in healthcare, finance, and policymaking.
- **Evaluation Metrics**: Assessing explanation quality.
- **Emerging Directions**: Interpretability in federated learning, ethical AI.

Hands-on Python examples and additional resources are available in the companion [GitHub repository](#).

---

## Features

- **Practical Techniques**: Explore actionable explainability techniques with Python code.
- **Real-World Applications**: Learn through case studies across diverse domains.
- **Emerging Research**: Gain insights into the latest trends, including interpretability for federated learning and ethical considerations.
- **Resources**: Complementary materials provided for further learning and development.

---

## Authors

The book is co-authored by experts in AI and machine learning:
Weiche Hsieh, Ziqian Bi, Chuanqi Jiang, Junyu Liu, Benji Peng, Sen Zhang, Xuanhe Pan, Jiawei Xu, Jinlang Wang, Keyu Chen, Caitlyn Heqi Yin, Pohsun Feng, Yizhu Wen, Xinyuan Song, Tianyang Wang, Junjie Yang, Ming Li, Bowen Jing, Jintao Ren, Junhao Song, Han Xu, Hong-Ming Tseng, Yichao Zhang, Lawrence K.Q. Yan, Qian Niu, Silin Chen, Yunze Wang, Chia Xin Liang, and Ming Liu.

---

## Citation

If you use this work in your research, please cite it as follows:

```bibtex
@misc{hsieh2024comprehensiveguideexplainableai,
      title={A Comprehensive Guide to Explainable AI: From Classical Models to LLMs}, 
      author={Weiche Hsieh and Ziqian Bi and Chuanqi Jiang and Junyu Liu and Benji Peng and Sen Zhang and Xuanhe Pan and Jiawei Xu and Jinlang Wang and Keyu Chen and Caitlyn Heqi Yin and Pohsun Feng and Yizhu Wen and Xinyuan Song and Tianyang Wang and Junjie Yang and Ming Li and Bowen Jing and Jintao Ren and Junhao Song and Han Xu and Hong-Ming Tseng and Yichao Zhang and Lawrence K. Q. Yan and Qian Niu and Silin Chen and Yunze Wang and Chia Xin Liang and Ming Liu},
      year={2024},
      eprint={2412.00800},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2412.00800}, 
}
